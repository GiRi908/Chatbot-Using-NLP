# NLP Chatbot with Logistic Regression and Streamlit

This project is a machine learning-powered chatbot built using Python. It leverages Natural Language Processing (NLP) techniques to understand user intent and provide relevant responses from a predefined knowledge base. The chatbot's core logic is based on a `Logistic Regression` model for intent classification, and the user interface is created with `Streamlit`, providing an interactive web-based experience.

---
## Features

* **Intent Recognition**: Understands user queries by classifying them into predefined intents using a TF-IDF Vectorizer and a Logistic Regression model.
* **Interactive Web UI**: A clean and user-friendly chat interface built with Streamlit.
* **Conversation Logging**: Automatically saves the conversation history (user input, chatbot response, timestamp) to a `chat_log.csv` file.
* **Conversation History Viewer**: A separate tab in the UI to view all past conversations.
* **Modular Knowledge Base**: Intents, user patterns, and bot responses are easily configurable in the `intents.json` file.
* **Model Evaluation**: The `chatbot.py` script provides a mechanism to train and evaluate the model's performance.

---
## Technologies Used

* **Python 3.x**
* **Scikit-learn**: For machine learning (`TfidfVectorizer`, `LogisticRegression`).
* **Streamlit**: For creating the web application UI.
* **NLTK**: For natural language processing tasks (tokenization).
* **Joblib**: For saving and loading the trained model.

---
## Project Structure

Chatbot_Project/
│
├── app.py                  # Main Streamlit application file
├── chatbot.py              # Script for training, evaluating, and saving the model
├── intents.json            # The knowledge base with intents, patterns, and responses
├── chat_log.csv            # (Generated) Log of all conversations
├── model.pkl               # (Generated by chatbot.py) The saved trained model
├── vectorizer.pkl          # (Generated by chatbot.py) The saved TF-IDF vectorizer
└── README.md               # This file


---
## How It Works

The chatbot operates in a few key steps:

1.  **Data Loading & Preprocessing**: The `intents.json` file is loaded. All the `patterns` and their corresponding `tags` (intents) are extracted.
2.  **Feature Extraction**: The text `patterns` are converted into numerical feature vectors using the Term Frequency-Inverse Document Frequency ($TF-IDF$) technique. This method evaluates how relevant a word is to a document in a collection of documents.
3.  **Model Training**: A `Logistic Regression` classifier is trained on the TF-IDF vectors (features) and the `tags` (labels). The model learns to associate specific words and phrases with their corresponding intents.
4.  **Inference (Chatting)**:
    * When a user enters a message, the input is transformed into a TF-IDF vector using the already-fitted vectorizer.
    * The trained classifier predicts the `tag` (intent) for this vector.
    * A random response is selected from the list of responses associated with the predicted `tag` in `intents.json`.

---
## Setup and Installation

Follow these steps to get the project running on your local machine.

**1. Clone the Repository**

```bash
git clone <your-repository-url>
cd Chatbot_Project
2. Create a Virtual Environment

It is highly recommended to use a virtual environment to manage project dependencies.

Bash

# For Windows
python -m venv venv
venv\Scripts\activate

# For macOS/Linux
python3 -m venv venv
source venv/bin/activate
3. Install Dependencies

Install all the required Python libraries using the following command:

Bash

pip install streamlit scikit-learn nltk joblib
4. Download NLTK Data

The NLTK library requires a specific dataset (punkt) for tokenization. The scripts will attempt to download this automatically. If you encounter issues, you can run this command in a Python shell:

Python

import nltk
nltk.download('punkt')
How to Run
There are two main scripts in this project.

1. Running the Web Application
To start the interactive chatbot application, run the app.py script using Streamlit.

Bash

streamlit run app.py
This will open a new tab in your web browser with the chatbot interface. You can start chatting, view conversation history, and read about the project.

2. Training and Evaluating the Model (Optional)
If you want to just train the model, evaluate its accuracy, and save the trained components (vectorizer.pkl and model.pkl), you can run the chatbot.py script.

Bash

python chatbot.py
This will print a classification report to the console, showing the model's performance on the test data, and save the model files to the root directory.

File Descriptions
intents.json: This is the brain of the chatbot. You can add new intents, patterns, and responses here to expand the chatbot's knowledge. Each intent object has a tag, a list of patterns (example user phrases), and a list of responses.

app.py: This file contains the code for the Streamlit web application. It handles the UI, loads the data, trains the model in memory, and manages the chatbot logic for real-time interaction and logging.

chatbot.py: A utility script for model development. It splits the data into training and testing sets, trains the model, evaluates its performance using metrics like precision, recall, and F1-score, and serializes the trained vectorizer and classifier to disk as .pkl files.
